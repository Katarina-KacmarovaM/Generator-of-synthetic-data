{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Katarina-KacmarovaM/Generator-of-synthetic-data/blob/main/Generic_Synthetic_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeKEceYFeeUs"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install -q requests bitsandbytes==0.46.0 transformers==4.48.3 accelerate==1.3.0 openai\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.3.0 torchvision==0.18.0 --upgrade --quiet\n",
        "!pip install --upgrade transformers accelerate safetensors --quiet"
      ],
      "metadata": {
        "id": "jxJXfvG0MfIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV81f8KjLLed"
      },
      "source": [
        "Need to write models that will generate data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-gubEZhDxeT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI\n",
        "from google.colab import drive\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCWKOxeQOG1p"
      },
      "source": [
        "## Need to create environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6BmjTUwOQ4D"
      },
      "outputs": [],
      "source": [
        "huggin_api_key = userdata.get(\"HF_TOKEN\")\n",
        "login(huggin_api_key, add_to_git_credential=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4B_KOb-PxWx"
      },
      "source": [
        "## MODELS THAT I'LL TRY FROM HF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdEmxjtpPxCc"
      },
      "outputs": [],
      "source": [
        "llama='meta-llama/Meta-Llama-3.1-8B-Instruct'\n",
        "qwen_alibaba='Qwen/Qwen2-7B-Instruct'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kULTzYtQ0JO"
      },
      "source": [
        "## Now I need to handle prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roXrNbx4Q55n"
      },
      "outputs": [],
      "source": [
        "system_prompt=\"You are data generation assistant that produces realistic,structured synthetic datasets for multi-modal multiagent AI system.Your task is to simulate realistic interactions between agents and users across tabular data,text, time series and structured data formats. \"\n",
        "\n",
        "\n",
        "\n",
        "user_prompt=\"\"\" Generate 50 telemedicine sessions. Each session object must include :\n",
        "  - session_id (UUID)\n",
        "  - patient_id, doctor_id\n",
        "  - start_time, end_time\n",
        "  - turns: list of {timestamp, speaker: \"Patient\"|\"Doctor\", content}\n",
        "  - vitals_timeseries: list of {timestamp, heart_rate, blood_pressure_systolic, blood_pressure_diastolic, temperature, respiratory_rate}\n",
        "  - summary: {avg_heart_rate, min_heart_rate, max_temperature, abnormal_readings_count}\n",
        "  - conclusion: {diagnosis, recommendations: [â€¦]}\n",
        "\n",
        " \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtrT_1aFcQgW"
      },
      "outputs": [],
      "source": [
        "def data_format(format):\n",
        "  if format=='JSON':\n",
        "    additional_prompt=\"The output will be only in JSON format.\"\n",
        "  elif format=='CSV':\n",
        "    additional_prompt=\"The output will be only in CSV format.\"\n",
        "  else:\n",
        "    additional_prompt=\"The output will be only in MarkDown format.\"\n",
        "  return additional_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teK_YiF2c5p6"
      },
      "outputs": [],
      "source": [
        "def model_messages(format):\n",
        "  messages=[{'role':'system','content':system_prompt},{'role':'user','content':user_prompt+data_format(format)}]\n",
        "\n",
        "  return messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK7znNamdmzb"
      },
      "source": [
        "## MODELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv6sQeJCd-9p"
      },
      "source": [
        "### First i will try quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktinFstEdkVi"
      },
      "outputs": [],
      "source": [
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liR4VRRze8QT"
      },
      "outputs": [],
      "source": [
        "def generate_model(messages,model_type):\n",
        "  tokenizer=AutoTokenizer.from_pretrained(model_type)\n",
        "  inputs=tokenizer.apply_chat_template(messages,add_generation_prompt=True,return_tensors=\"pt\").to(\"cuda\")\n",
        "  streamer=TextStreamer(tokenizer)\n",
        "  model = AutoModelForCausalLM.from_pretrained(model_type, device_map=\"auto\", quantization_config=quant_config)\n",
        "  outputs=model.generate(inputs,streamer=streamer,max_new_tokens=2000)\n",
        "  response = tokenizer.decode(outputs[0])\n",
        "\n",
        "  return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2e1BBUKgwRk"
      },
      "outputs": [],
      "source": [
        "def generate_dataset(model_choice, format):\n",
        "    if model_choice=='meta':\n",
        "      model_type=llama\n",
        "    else:\n",
        "      model_type=qwen_alibaba\n",
        "\n",
        "    messages = model_messages(format)\n",
        "    dataset = generate_model(messages, model_type)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBiHozgdh9Ri"
      },
      "source": [
        "## Now i will create Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUA_v2HNh86s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a52c4e3f"
      },
      "outputs": [],
      "source": [
        "%pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb588026"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "model_choices = ['meta', 'qwen']\n",
        "format_choices = ['JSON', 'CSV', 'MarkDown']\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=generate_dataset,\n",
        "    inputs=[\n",
        "        gr.Dropdown(model_choices, label=\"Select Model\"),\n",
        "        gr.Dropdown(format_choices, label=\"Select Format\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Generated Dataset\"),\n",
        "    title=\"Synthetic Telemedicine Dataset Generator\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77f2f777",
        "outputId": "abeca09e-b753-4276-97cc-585449b419c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://e9f8cea99092f76a97.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "iface.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOvePaz0l1pw1FwmqrgyC4P",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}